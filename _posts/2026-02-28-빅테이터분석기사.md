---
title: "[ë¹…ë°ì´í„°ë¶„ì„ê¸°ì‚¬] Python/R"
date: 2026-02-28 01:00:00 +0900
---

## 1. ë°ì´í„° ë¡œë“œ ë° êµ¬ì¡° í™•ì¸

| **ê¸°ëŠ¥** | **Python (Pandas)** | **R** |
| --- | --- | --- |
| **ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°** | `pd.read_csv("file.csv")` | `read.csv("file.csv")` |
| **í–‰ë ¬ í¬ê¸° í™•ì¸** | `data.shape` | `dim(data)` |
| **ì»¬ëŸ¼ëª… í™•ì¸** | `data.columns` | `colnames(data)` |
| **ê¸°ì´ˆ í†µê³„ëŸ‰** | `data.describe()` | `summary(data)` |
| **ë°ì´í„° ìš”ì•½ ì •ë³´** | `data.info()` | `str(data)` |

## 2. ë°ì´í„° ì „ì²˜ë¦¬ ë° ê°€ê³µ

| **ê¸°ëŠ¥** | **Python (Pandas)** | **R** |
| --- | --- | --- |
| **ë°ì´í„° ì •ë ¬** | `sort_values(by=['C1'], ascending=False)` | `data[order(-data$C1), ]` |
| **ì¤‘ë³µ ì œê±° ê°’** | `data['col'].unique()` | `unique(data$col)` |
| **ìƒê´€ê´€ê³„ êµ¬í•˜ê¸°** | `data.corr()` | `cor(data)` |
| **ê²°ì¸¡ì¹˜ í™•ì¸** | `data.isnull().sum()` | `colSums(is.na(data))` |
| **ê²°ì¸¡ì¹˜ ëŒ€ì¹˜(í‰ê· )** | `fillna(data['col'].mean())` | `data$col[is.na(data$col)] <- mean(...)` |
| **ê°’ ë³€ê²½(Replace)** | `replace('A', 'B')` | `ifelse(data$col == 'A', 'B', data$col)` |
| **íƒ€ì… ë³€ê²½** | `astype('int64')` | `as.integer(data$col)` |
| **íŒŒìƒë³€ìˆ˜ ìƒì„±** | `data.loc[cond, 'new'] = 1` | `data$new <- ifelse(cond, 1, 0)` |

## 3. ë¨¸ì‹ ëŸ¬ë‹ í”„ë¡œì„¸ìŠ¤

| **ê¸°ëŠ¥** | **Python (Scikit-learn)** | **R** |
| --- | --- | --- |
| **ë°ì´í„° ë¶„ë¦¬** | `train_test_split(X, Y, test_size=0.3)` | `createDataPartition(Y, p=0.7)` |
| **ìŠ¤ì¼€ì¼ë§(í‘œì¤€í™”)** | `StandardScaler().fit_transform(data)` | `scale(data)` |
| **ì›í•« ì¸ì½”ë”©** | `pd.get_dummies(data['col'])` | `dummy_cols(data, select_columns='col')` |
| **ì„ í˜• íšŒê·€** | `LinearRegression().fit(x, y)` | `lm(y ~ ., data=train)` |
| **ëœë¤ í¬ë ˆìŠ¤íŠ¸** | `RandomForestClassifier().fit(x, y)` | `randomForest(y ~ ., data=train)` |
| **ì˜ˆì¸¡í•˜ê¸°** | `model.predict(x_test)` | `predict(model, newdata=test)` |
| **í™•ë¥ ê°’ ì˜ˆì¸¡** | `model.predict_proba(x_test)` | `predict(model, type="response")` |

## 4. í†µê³„ ê²€ì • (ì œ 3ìœ í˜•)

| **ê¸°ëŠ¥** | **Python (Scipy/Statsmodels)** | **R** |
| --- | --- | --- |
| **ë‹¨ì¼í‘œë³¸ t-ê²€ì •** | `stats.ttest_1samp(data, popmean)` | `t.test(data, mu=160)` |
| **ë…ë¦½í‘œë³¸ t-ê²€ì •** | `stats.ttest_ind(a, b, equal_var=True)` | `t.test(a, b, var.equal=TRUE)` |
| **ëŒ€ì‘í‘œë³¸ t-ê²€ì •** | `stats.ttest_rel(after, before)` | `t.test(after, before, paired=TRUE)` |
| **ANOVA (ë¶„ì‚°ë¶„ì„)** | `stats.f_oneway(a, b, c)` | `aov(y ~ group, data=df)` |
| **ì¹´ì´ì œê³± ê²€ì •** | `stats.chi2_contingency(table)` | `chisq.test(table)` |
| **ìœŒì½•ìŠ¨ ë¶€í˜¸ê²€ì •** | `stats.wilcoxon(after, before)` | `wilcox.test(after, before, paired=TRUE)` |

## 5. ê²°ê³¼ ì €ì¥

| **ê¸°ëŠ¥** | **Python (Pandas)** | **R** |
| --- | --- | --- |
| **CSV ì €ì¥** | `df.to_csv('res.csv', index=False)` | `write.csv(df, 'res.csv', row.names=F)` |

## ğŸ› ï¸  dir() & help() í™œìš© ê°€ì´ë“œ

### 1. `dir()` : "ë¬´ìŠ¨ ê¸°ëŠ¥ì´ ìˆì§€?" (ëª©ë¡ í™•ì¸)

ê°ì²´ê°€ ê°€ì§€ê³  ìˆëŠ” ë©”ì„œë“œë‚˜ ë³€ìˆ˜ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³´ì—¬ì¤Œ. íŠ¹ì • ë‹¨ì–´ê°€ í¬í•¨ëœ ê¸°ëŠ¥ì„ ì°¾ì„ ë•Œ `list comprehension`ê³¼ í•¨ê»˜ ì“°ë©´ ë” ê°•ë ¥.

| **ëŒ€ìƒ** | **ëª…ë ¹ì–´** | **í™œìš© ëª©ì ** |
| --- | --- | --- |
| **íŒ¨í‚¤ì§€ ì „ì²´** | `print(dir(pd))` | íŒë‹¤ìŠ¤ì—ì„œ ì“¸ ìˆ˜ ìˆëŠ” ì „ì²´ ê¸°ëŠ¥ í™•ì¸ |
| **ë°ì´í„°í”„ë ˆì„** | `print(dir(pd.DataFrame))` | `sort_values`, `groupby`, `fillna` ë“± ë©”ì„œë“œ í™•ì¸ |
| **ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë“ˆ** | `print(dir(sklearn.ensemble))` | `RandomForest`, `GradientBoosting` ë“± ëª¨ë¸ëª… í™•ì¸ |
| **ì „ì²˜ë¦¬ ëª¨ë“ˆ** | `print(dir(sklearn.preprocessing))` | `StandardScaler`, `LabelEncoder` ë“± í™•ì¸ |
| **í†µê³„ ê²€ì •** | `print(dir(scipy.stats))` | `ttest`, `chisquare`, `f_oneway` ë“± í™•ì¸ |

**ğŸ’¡ í•„í„°ë§í•´ì„œ ì°¾ê¸°**

`Standard`ê°€ ë“¤ì–´ê°„ ì „ì²˜ë¦¬ ë„êµ¬ë¥¼ ì°¾ê³  ì‹¶ë‹¤ë©´?

```python
print([m for m in dir(sklearn.preprocessing) if 'Standard' in m])
```

### 2. `help()` : "ì–´ë–»ê²Œ ì“°ì§€?" (ì‚¬ìš©ë²• í™•ì¸)

í•¨ìˆ˜ì˜ íŒŒë¼ë¯¸í„°, ë°˜í™˜ê°’, ì˜ˆì œ ì½”ë“œë¥¼ ë³´ì—¬ì¤Œ.

| **ëŒ€ìƒ** | **ëª…ë ¹ì–´** | **í™•ì¸í•´ì•¼ í•  ì£¼ìš” íŒŒë¼ë¯¸í„°** |
| --- | --- | --- |
| **ë°ì´í„° ì •ë ¬** | `help(pd.DataFrame.sort_values)` | `by`, `ascending` (ë‚´ë¦¼ì°¨ìˆœ ì—¬ë¶€) |
| **ê·¸ë£¹í™”** | `help(pd.DataFrame.groupby)` | `by`, `as_index` (ì¸ë±ìŠ¤ ìœ ì§€ ì—¬ë¶€) |
| **ëª¨ë¸ í•™ìŠµ** | `help(RandomForestRegressor)` | `n_estimators`, `max_depth`, `random_state` |
| **ë°ì´í„° ë¶„í• ** | `help(sklearn.model_selection.train_test_split)` | `test_size`, `stratify`, `shuffle` |
| **í†µê³„ ê²€ì •** | `help(scipy.stats.ttest_ind)` | `alternative`('less', 'greater'), `equal_var` |

### 3. ì‹œí—˜ ì§ì „ "ê¸°ì–µ í™˜ê¸°"ìš© ìš”ì•½ ë¦¬ìŠ¤íŠ¸

ì‹œí—˜ ì‹œì‘ ì§í›„, ì•„ë˜ ì½”ë“œë“¤ì„ ë¨¸ë¦¿ì†ìœ¼ë¡œ ê·¸ë¦¬ê±°ë‚˜ ì—°ìŠµë€ì— ë©”ëª¨.

```python
# 1. ê²½ë¡œê°€ ê¸°ì–µ ì•ˆ ë‚  ë•Œ

import sklearn
print(dir(sklearn)) # ì—¬ê¸°ì„œ model_selection, ensemble ë“±ì„ í™•ì¸

# 2. ëª¨ë¸ íŒŒë¼ë¯¸í„°ê°€ ê¸°ì–µ ì•ˆ ë‚  ë•Œ (ì˜ˆ: n_estimatorsì¸ì§€ estimatorsì¸ì§€)

from sklearn.ensemble import RandomForestClassifier
help(RandomForestClassifier)

# 3. í†µê³„ ê²€ì • ì‹œ p-value ì¶œë ¥ í˜•íƒœê°€ ê¶ê¸ˆí•  ë•Œ

import scipy.stats as stats
help(stats.ttest_ind) # ê²°ê³¼ê°’ì´ (statistic, pvalue) ìˆœì„œì¸ ê²ƒ í™•ì¸
```

## âš ï¸ ì£¼ì˜ì‚¬í•­ (í•„ìˆ˜ ì²´í¬)

> 1. **ëŒ€ì†Œë¬¸ì êµ¬ë¶„**: `help(pd.dataframe)`ì€ ì—ëŸ¬ ë‚¨. ë°˜ë“œì‹œ `pd.DataFrame`ì²˜ëŸ¼ ëŒ€ì†Œë¬¸ìë¥¼ ì •í™•íˆ ì ì–´ì•¼ í•¨.
> 2. **ê´„í˜¸ ì œì™¸**: `help(pd.read_csv)`ì²˜ëŸ¼ í•¨ìˆ˜ ì´ë¦„ë§Œ ì ê¸°. `help(pd.read_csv())`ëŠ” í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•œ ê²°ê³¼ë¥¼ ë„ì›€ë§ë¡œ ë³´ì—¬ì£¼ë ¤ í•˜ë¯€ë¡œ ì—ëŸ¬ê°€ ë‚  í™•ë¥ ì´ ë†’ìŒ.
> 3. **ì¶œë ¥ ì–‘**: `help()`ëŠ” ë‚´ìš©ì´ ë§¤ìš° ê¸¸ì–´ í™”ë©´ì„ ë§ì´ ì°¨ì§€í•  ìˆ˜ ìˆìœ¼ë‹ˆ, í•„ìš”í•œ ë¶€ë¶„ì„ í™•ì¸í•˜ë©´ ì¦‰ì‹œ ì§€ìš°ê±°ë‚˜ ì£¼ì„ ì²˜ë¦¬í•˜ì—¬ ì½”ë“œë¥¼ ê¹”ë”í•˜ê²Œ ìœ ì§€.